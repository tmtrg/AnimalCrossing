{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thuym\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Chargement les données\n",
    "data_path = 'turnips2.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Calcul des profits pour chaque demi-journée\n",
    "columns = ['Mon-AM', 'Mon-PM', 'Tues-AM', 'Tues-PM', 'Wed-AM', 'Wed-PM', 'Thurs-AM', 'Thurs-PM', 'Fri-AM', 'Fri-PM', 'Sat-AM', 'Sat-PM']\n",
    "for col in columns:\n",
    "    data[col] = data[col] - data['Purchase']\n",
    "\n",
    "# Normalisation les données\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[columns])\n",
    "\n",
    "# Clustering pour identifier les tendances\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(data_scaled)\n",
    "data['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thuym\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2400/2400 - 5s - loss: 0.5893 - accuracy: 0.7406 - val_loss: 0.4571 - val_accuracy: 0.7863 - 5s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "2400/2400 - 4s - loss: 0.4923 - accuracy: 0.7759 - val_loss: 0.4417 - val_accuracy: 0.7904 - 4s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "2400/2400 - 4s - loss: 0.4744 - accuracy: 0.7796 - val_loss: 0.4340 - val_accuracy: 0.7893 - 4s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "2400/2400 - 6s - loss: 0.4666 - accuracy: 0.7811 - val_loss: 0.4314 - val_accuracy: 0.7914 - 6s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "2400/2400 - 5s - loss: 0.4598 - accuracy: 0.7840 - val_loss: 0.4252 - val_accuracy: 0.7901 - 5s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "2400/2400 - 5s - loss: 0.4547 - accuracy: 0.7854 - val_loss: 0.4219 - val_accuracy: 0.7902 - 5s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "2400/2400 - 4s - loss: 0.4519 - accuracy: 0.7858 - val_loss: 0.4190 - val_accuracy: 0.7913 - 4s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "2400/2400 - 5s - loss: 0.4500 - accuracy: 0.7859 - val_loss: 0.4160 - val_accuracy: 0.7949 - 5s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "2400/2400 - 5s - loss: 0.4470 - accuracy: 0.7882 - val_loss: 0.4160 - val_accuracy: 0.7934 - 5s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "2400/2400 - 4s - loss: 0.4436 - accuracy: 0.7884 - val_loss: 0.4130 - val_accuracy: 0.7962 - 4s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "2400/2400 - 6s - loss: 0.4439 - accuracy: 0.7881 - val_loss: 0.4129 - val_accuracy: 0.7928 - 6s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "2400/2400 - 6s - loss: 0.4428 - accuracy: 0.7896 - val_loss: 0.4109 - val_accuracy: 0.7968 - 6s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "2400/2400 - 4s - loss: 0.4434 - accuracy: 0.7893 - val_loss: 0.4120 - val_accuracy: 0.7936 - 4s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "2400/2400 - 5s - loss: 0.4408 - accuracy: 0.7890 - val_loss: 0.4114 - val_accuracy: 0.7977 - 5s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "2400/2400 - 5s - loss: 0.4431 - accuracy: 0.7887 - val_loss: 0.4100 - val_accuracy: 0.7958 - 5s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "2400/2400 - 5s - loss: 0.4402 - accuracy: 0.7884 - val_loss: 0.4080 - val_accuracy: 0.7964 - 5s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "2400/2400 - 5s - loss: 0.4391 - accuracy: 0.7896 - val_loss: 0.4070 - val_accuracy: 0.7953 - 5s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "2400/2400 - 5s - loss: 0.4384 - accuracy: 0.7898 - val_loss: 0.4086 - val_accuracy: 0.7939 - 5s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "2400/2400 - 5s - loss: 0.4402 - accuracy: 0.7885 - val_loss: 0.4076 - val_accuracy: 0.7942 - 5s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "2400/2400 - 5s - loss: 0.4392 - accuracy: 0.7888 - val_loss: 0.4084 - val_accuracy: 0.7943 - 5s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "2400/2400 - 5s - loss: 0.4371 - accuracy: 0.7922 - val_loss: 0.4081 - val_accuracy: 0.7959 - 5s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "2400/2400 - 5s - loss: 0.4369 - accuracy: 0.7899 - val_loss: 0.4041 - val_accuracy: 0.7967 - 5s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "2400/2400 - 4s - loss: 0.4362 - accuracy: 0.7912 - val_loss: 0.4051 - val_accuracy: 0.7966 - 4s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "2400/2400 - 4s - loss: 0.4361 - accuracy: 0.7899 - val_loss: 0.4075 - val_accuracy: 0.7957 - 4s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "2400/2400 - 4s - loss: 0.4341 - accuracy: 0.7901 - val_loss: 0.4051 - val_accuracy: 0.7991 - 4s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "2400/2400 - 5s - loss: 0.4344 - accuracy: 0.7917 - val_loss: 0.4070 - val_accuracy: 0.7953 - 5s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "2400/2400 - 5s - loss: 0.4343 - accuracy: 0.7923 - val_loss: 0.4049 - val_accuracy: 0.7998 - 5s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "2400/2400 - 5s - loss: 0.4336 - accuracy: 0.7903 - val_loss: 0.4044 - val_accuracy: 0.7959 - 5s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "2400/2400 - 5s - loss: 0.4348 - accuracy: 0.7923 - val_loss: 0.4055 - val_accuracy: 0.7960 - 5s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "2400/2400 - 4s - loss: 0.4343 - accuracy: 0.7934 - val_loss: 0.4043 - val_accuracy: 0.8008 - 4s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "2400/2400 - 4s - loss: 0.4331 - accuracy: 0.7922 - val_loss: 0.4061 - val_accuracy: 0.7997 - 4s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "2400/2400 - 5s - loss: 0.4325 - accuracy: 0.7923 - val_loss: 0.4039 - val_accuracy: 0.7963 - 5s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "2400/2400 - 5s - loss: 0.4338 - accuracy: 0.7916 - val_loss: 0.4037 - val_accuracy: 0.7995 - 5s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "2400/2400 - 5s - loss: 0.4327 - accuracy: 0.7922 - val_loss: 0.4063 - val_accuracy: 0.7949 - 5s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "2400/2400 - 5s - loss: 0.4340 - accuracy: 0.7907 - val_loss: 0.4028 - val_accuracy: 0.7993 - 5s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "2400/2400 - 5s - loss: 0.4328 - accuracy: 0.7911 - val_loss: 0.4066 - val_accuracy: 0.7979 - 5s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "2400/2400 - 5s - loss: 0.4346 - accuracy: 0.7912 - val_loss: 0.4040 - val_accuracy: 0.7983 - 5s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "2400/2400 - 5s - loss: 0.4312 - accuracy: 0.7935 - val_loss: 0.4000 - val_accuracy: 0.8003 - 5s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "2400/2400 - 5s - loss: 0.4319 - accuracy: 0.7923 - val_loss: 0.4044 - val_accuracy: 0.7969 - 5s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "2400/2400 - 5s - loss: 0.4327 - accuracy: 0.7925 - val_loss: 0.4034 - val_accuracy: 0.7994 - 5s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "2400/2400 - 5s - loss: 0.4319 - accuracy: 0.7928 - val_loss: 0.4035 - val_accuracy: 0.7985 - 5s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "2400/2400 - 5s - loss: 0.4332 - accuracy: 0.7910 - val_loss: 0.4013 - val_accuracy: 0.7984 - 5s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "2400/2400 - 5s - loss: 0.4325 - accuracy: 0.7916 - val_loss: 0.4023 - val_accuracy: 0.7979 - 5s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "2400/2400 - 5s - loss: 0.4307 - accuracy: 0.7936 - val_loss: 0.4018 - val_accuracy: 0.7997 - 5s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "2400/2400 - 5s - loss: 0.4346 - accuracy: 0.7905 - val_loss: 0.4011 - val_accuracy: 0.8020 - 5s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "2400/2400 - 6s - loss: 0.4310 - accuracy: 0.7925 - val_loss: 0.4012 - val_accuracy: 0.8016 - 6s/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "2400/2400 - 5s - loss: 0.4303 - accuracy: 0.7939 - val_loss: 0.4013 - val_accuracy: 0.8012 - 5s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "2400/2400 - 5s - loss: 0.4324 - accuracy: 0.7917 - val_loss: 0.4027 - val_accuracy: 0.7983 - 5s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "2400/2400 - 5s - loss: 0.4315 - accuracy: 0.7921 - val_loss: 0.4014 - val_accuracy: 0.7984 - 5s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "2400/2400 - 5s - loss: 0.4311 - accuracy: 0.7937 - val_loss: 0.4014 - val_accuracy: 0.8001 - 5s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "2400/2400 - 5s - loss: 0.4312 - accuracy: 0.7925 - val_loss: 0.4019 - val_accuracy: 0.7990 - 5s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "2400/2400 - 5s - loss: 0.4306 - accuracy: 0.7933 - val_loss: 0.4016 - val_accuracy: 0.8015 - 5s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "2400/2400 - 4s - loss: 0.4315 - accuracy: 0.7921 - val_loss: 0.4048 - val_accuracy: 0.7969 - 4s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "2400/2400 - 4s - loss: 0.4295 - accuracy: 0.7927 - val_loss: 0.4000 - val_accuracy: 0.8003 - 4s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "2400/2400 - 4s - loss: 0.4329 - accuracy: 0.7926 - val_loss: 0.4028 - val_accuracy: 0.7976 - 4s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "2400/2400 - 4s - loss: 0.4299 - accuracy: 0.7939 - val_loss: 0.4004 - val_accuracy: 0.7984 - 4s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "2400/2400 - 4s - loss: 0.4295 - accuracy: 0.7940 - val_loss: 0.4025 - val_accuracy: 0.8033 - 4s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "2400/2400 - 4s - loss: 0.4307 - accuracy: 0.7927 - val_loss: 0.4048 - val_accuracy: 0.7983 - 4s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "2400/2400 - 4s - loss: 0.4299 - accuracy: 0.7931 - val_loss: 0.4084 - val_accuracy: 0.7972 - 4s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "2400/2400 - 4s - loss: 0.4307 - accuracy: 0.7915 - val_loss: 0.4012 - val_accuracy: 0.7991 - 4s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "2400/2400 - 4s - loss: 0.4297 - accuracy: 0.7932 - val_loss: 0.4012 - val_accuracy: 0.7977 - 4s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "2400/2400 - 4s - loss: 0.4261 - accuracy: 0.7940 - val_loss: 0.3993 - val_accuracy: 0.8032 - 4s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "2400/2400 - 4s - loss: 0.4281 - accuracy: 0.7947 - val_loss: 0.4026 - val_accuracy: 0.7982 - 4s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "2400/2400 - 4s - loss: 0.4293 - accuracy: 0.7922 - val_loss: 0.4021 - val_accuracy: 0.8013 - 4s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "2400/2400 - 4s - loss: 0.4297 - accuracy: 0.7932 - val_loss: 0.4018 - val_accuracy: 0.8014 - 4s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "2400/2400 - 4s - loss: 0.4284 - accuracy: 0.7929 - val_loss: 0.4011 - val_accuracy: 0.7988 - 4s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "2400/2400 - 4s - loss: 0.4290 - accuracy: 0.7943 - val_loss: 0.3998 - val_accuracy: 0.7991 - 4s/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "2400/2400 - 4s - loss: 0.4283 - accuracy: 0.7930 - val_loss: 0.4010 - val_accuracy: 0.7983 - 4s/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "2400/2400 - 4s - loss: 0.4287 - accuracy: 0.7940 - val_loss: 0.4003 - val_accuracy: 0.7989 - 4s/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "2400/2400 - 5s - loss: 0.4284 - accuracy: 0.7950 - val_loss: 0.4003 - val_accuracy: 0.7997 - 5s/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "2400/2400 - 4s - loss: 0.4276 - accuracy: 0.7935 - val_loss: 0.4031 - val_accuracy: 0.7975 - 4s/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "2400/2400 - 5s - loss: 0.4280 - accuracy: 0.7940 - val_loss: 0.4000 - val_accuracy: 0.8015 - 5s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "2400/2400 - 5s - loss: 0.4288 - accuracy: 0.7948 - val_loss: 0.4054 - val_accuracy: 0.7982 - 5s/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "2400/2400 - 5s - loss: 0.4298 - accuracy: 0.7930 - val_loss: 0.4020 - val_accuracy: 0.8000 - 5s/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "2400/2400 - 5s - loss: 0.4273 - accuracy: 0.7933 - val_loss: 0.4003 - val_accuracy: 0.7983 - 5s/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "2400/2400 - 5s - loss: 0.4286 - accuracy: 0.7941 - val_loss: 0.3989 - val_accuracy: 0.8001 - 5s/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "2400/2400 - 6s - loss: 0.4294 - accuracy: 0.7930 - val_loss: 0.4014 - val_accuracy: 0.7967 - 6s/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "2400/2400 - 5s - loss: 0.4292 - accuracy: 0.7935 - val_loss: 0.4011 - val_accuracy: 0.7993 - 5s/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "2400/2400 - 5s - loss: 0.4291 - accuracy: 0.7942 - val_loss: 0.3998 - val_accuracy: 0.8004 - 5s/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "2400/2400 - 5s - loss: 0.4278 - accuracy: 0.7930 - val_loss: 0.3995 - val_accuracy: 0.7990 - 5s/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "2400/2400 - 5s - loss: 0.4274 - accuracy: 0.7958 - val_loss: 0.3997 - val_accuracy: 0.8032 - 5s/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "2400/2400 - 6s - loss: 0.4286 - accuracy: 0.7931 - val_loss: 0.4016 - val_accuracy: 0.7999 - 6s/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "2400/2400 - 6s - loss: 0.4280 - accuracy: 0.7934 - val_loss: 0.4001 - val_accuracy: 0.7990 - 6s/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "2400/2400 - 6s - loss: 0.4288 - accuracy: 0.7934 - val_loss: 0.4017 - val_accuracy: 0.7956 - 6s/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "2400/2400 - 5s - loss: 0.4282 - accuracy: 0.7934 - val_loss: 0.4020 - val_accuracy: 0.7990 - 5s/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "2400/2400 - 4s - loss: 0.4291 - accuracy: 0.7934 - val_loss: 0.4013 - val_accuracy: 0.8001 - 4s/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "2400/2400 - 4s - loss: 0.4276 - accuracy: 0.7935 - val_loss: 0.4038 - val_accuracy: 0.7986 - 4s/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "2400/2400 - 4s - loss: 0.4280 - accuracy: 0.7942 - val_loss: 0.3994 - val_accuracy: 0.7986 - 4s/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "2400/2400 - 4s - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.4011 - val_accuracy: 0.7999 - 4s/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "2400/2400 - 4s - loss: 0.4278 - accuracy: 0.7930 - val_loss: 0.4017 - val_accuracy: 0.7995 - 4s/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "2400/2400 - 4s - loss: 0.4264 - accuracy: 0.7938 - val_loss: 0.4023 - val_accuracy: 0.7987 - 4s/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "2400/2400 - 4s - loss: 0.4267 - accuracy: 0.7942 - val_loss: 0.3992 - val_accuracy: 0.8017 - 4s/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "2400/2400 - 4s - loss: 0.4273 - accuracy: 0.7946 - val_loss: 0.4030 - val_accuracy: 0.7987 - 4s/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "2400/2400 - 4s - loss: 0.4279 - accuracy: 0.7933 - val_loss: 0.4007 - val_accuracy: 0.7971 - 4s/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "2400/2400 - 4s - loss: 0.4278 - accuracy: 0.7942 - val_loss: 0.3999 - val_accuracy: 0.7989 - 4s/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "2400/2400 - 4s - loss: 0.4290 - accuracy: 0.7941 - val_loss: 0.3982 - val_accuracy: 0.7998 - 4s/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "2400/2400 - 4s - loss: 0.4262 - accuracy: 0.7931 - val_loss: 0.3993 - val_accuracy: 0.7974 - 4s/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "2400/2400 - 4s - loss: 0.4282 - accuracy: 0.7934 - val_loss: 0.3990 - val_accuracy: 0.7998 - 4s/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "2400/2400 - 4s - loss: 0.4274 - accuracy: 0.7949 - val_loss: 0.3993 - val_accuracy: 0.7994 - 4s/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "2400/2400 - 4s - loss: 0.4281 - accuracy: 0.7943 - val_loss: 0.3995 - val_accuracy: 0.8027 - 4s/epoch - 2ms/step\n",
      "Test accuracy: 0.7978164553642273\n"
     ]
    }
   ],
   "source": [
    "# Encoder les labels de cluster en format one-hot pour l'entraînement du réseau de neurones\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))  # Utilisez .values pour convertir en numpy array\n",
    "y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Construire le modèle\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(y_train_encoded.shape[1], activation='softmax')  # La couche de sortie a un neurone par classe\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(X_train, y_train_encoded, epochs=100, batch_size=32, validation_split=0.2, verbose=2)\n",
    "\n",
    "# Évaluer le modèle sur l'ensemble de test\n",
    "loss, accuracy = model.evaluate(X_test, y_test_encoded, verbose=0)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1200/1200 - 4s - loss: 0.7091 - accuracy: 0.7387 - val_loss: 0.5502 - val_accuracy: 0.7837 - 4s/epoch - 3ms/step\n",
      "Epoch 2/150\n",
      "1200/1200 - 3s - loss: 0.5591 - accuracy: 0.7755 - val_loss: 0.5063 - val_accuracy: 0.7906 - 3s/epoch - 2ms/step\n",
      "Epoch 3/150\n",
      "1200/1200 - 3s - loss: 0.5256 - accuracy: 0.7800 - val_loss: 0.4882 - val_accuracy: 0.7910 - 3s/epoch - 2ms/step\n",
      "Epoch 4/150\n",
      "1200/1200 - 3s - loss: 0.5093 - accuracy: 0.7826 - val_loss: 0.4814 - val_accuracy: 0.7937 - 3s/epoch - 2ms/step\n",
      "Epoch 5/150\n",
      "1200/1200 - 3s - loss: 0.4984 - accuracy: 0.7863 - val_loss: 0.4707 - val_accuracy: 0.7956 - 3s/epoch - 2ms/step\n",
      "Epoch 6/150\n",
      "1200/1200 - 3s - loss: 0.4931 - accuracy: 0.7861 - val_loss: 0.4664 - val_accuracy: 0.7951 - 3s/epoch - 2ms/step\n",
      "Epoch 7/150\n",
      "1200/1200 - 3s - loss: 0.4870 - accuracy: 0.7882 - val_loss: 0.4628 - val_accuracy: 0.7953 - 3s/epoch - 2ms/step\n",
      "Epoch 8/150\n",
      "1200/1200 - 3s - loss: 0.4823 - accuracy: 0.7891 - val_loss: 0.4599 - val_accuracy: 0.7961 - 3s/epoch - 2ms/step\n",
      "Epoch 9/150\n",
      "1200/1200 - 3s - loss: 0.4795 - accuracy: 0.7895 - val_loss: 0.4546 - val_accuracy: 0.7980 - 3s/epoch - 2ms/step\n",
      "Epoch 10/150\n",
      "1200/1200 - 3s - loss: 0.4768 - accuracy: 0.7896 - val_loss: 0.4544 - val_accuracy: 0.7979 - 3s/epoch - 2ms/step\n",
      "Epoch 11/150\n",
      "1200/1200 - 3s - loss: 0.4746 - accuracy: 0.7900 - val_loss: 0.4519 - val_accuracy: 0.7976 - 3s/epoch - 3ms/step\n",
      "Epoch 12/150\n",
      "1200/1200 - 3s - loss: 0.4722 - accuracy: 0.7905 - val_loss: 0.4524 - val_accuracy: 0.7960 - 3s/epoch - 2ms/step\n",
      "Epoch 13/150\n",
      "1200/1200 - 3s - loss: 0.4705 - accuracy: 0.7910 - val_loss: 0.4487 - val_accuracy: 0.8006 - 3s/epoch - 2ms/step\n",
      "Epoch 14/150\n",
      "1200/1200 - 3s - loss: 0.4683 - accuracy: 0.7922 - val_loss: 0.4476 - val_accuracy: 0.7986 - 3s/epoch - 2ms/step\n",
      "Epoch 15/150\n",
      "1200/1200 - 3s - loss: 0.4674 - accuracy: 0.7927 - val_loss: 0.4477 - val_accuracy: 0.8012 - 3s/epoch - 3ms/step\n",
      "Epoch 16/150\n",
      "1200/1200 - 4s - loss: 0.4661 - accuracy: 0.7927 - val_loss: 0.4448 - val_accuracy: 0.8014 - 4s/epoch - 3ms/step\n",
      "Epoch 17/150\n",
      "1200/1200 - 3s - loss: 0.4653 - accuracy: 0.7928 - val_loss: 0.4451 - val_accuracy: 0.8004 - 3s/epoch - 3ms/step\n",
      "Epoch 18/150\n",
      "1200/1200 - 3s - loss: 0.4641 - accuracy: 0.7929 - val_loss: 0.4436 - val_accuracy: 0.8009 - 3s/epoch - 3ms/step\n",
      "Epoch 19/150\n",
      "1200/1200 - 3s - loss: 0.4622 - accuracy: 0.7938 - val_loss: 0.4440 - val_accuracy: 0.8012 - 3s/epoch - 3ms/step\n",
      "Epoch 20/150\n",
      "1200/1200 - 3s - loss: 0.4616 - accuracy: 0.7939 - val_loss: 0.4408 - val_accuracy: 0.8007 - 3s/epoch - 3ms/step\n",
      "Epoch 21/150\n",
      "1200/1200 - 3s - loss: 0.4616 - accuracy: 0.7933 - val_loss: 0.4410 - val_accuracy: 0.8008 - 3s/epoch - 3ms/step\n",
      "Epoch 22/150\n",
      "1200/1200 - 3s - loss: 0.4592 - accuracy: 0.7944 - val_loss: 0.4417 - val_accuracy: 0.8004 - 3s/epoch - 3ms/step\n",
      "Epoch 23/150\n",
      "1200/1200 - 3s - loss: 0.4599 - accuracy: 0.7935 - val_loss: 0.4420 - val_accuracy: 0.7997 - 3s/epoch - 3ms/step\n",
      "Epoch 24/150\n",
      "1200/1200 - 4s - loss: 0.4596 - accuracy: 0.7939 - val_loss: 0.4398 - val_accuracy: 0.8014 - 4s/epoch - 3ms/step\n",
      "Epoch 25/150\n",
      "1200/1200 - 3s - loss: 0.4586 - accuracy: 0.7938 - val_loss: 0.4386 - val_accuracy: 0.7985 - 3s/epoch - 3ms/step\n",
      "Epoch 26/150\n",
      "1200/1200 - 3s - loss: 0.4565 - accuracy: 0.7938 - val_loss: 0.4380 - val_accuracy: 0.8003 - 3s/epoch - 3ms/step\n",
      "Epoch 27/150\n",
      "1200/1200 - 3s - loss: 0.4577 - accuracy: 0.7937 - val_loss: 0.4397 - val_accuracy: 0.7979 - 3s/epoch - 3ms/step\n",
      "Epoch 28/150\n",
      "1200/1200 - 3s - loss: 0.4573 - accuracy: 0.7941 - val_loss: 0.4386 - val_accuracy: 0.7991 - 3s/epoch - 3ms/step\n",
      "Epoch 29/150\n",
      "1200/1200 - 4s - loss: 0.4554 - accuracy: 0.7936 - val_loss: 0.4388 - val_accuracy: 0.8001 - 4s/epoch - 3ms/step\n",
      "Epoch 30/150\n",
      "1200/1200 - 3s - loss: 0.4561 - accuracy: 0.7948 - val_loss: 0.4383 - val_accuracy: 0.8001 - 3s/epoch - 3ms/step\n",
      "Epoch 31/150\n",
      "1200/1200 - 3s - loss: 0.4548 - accuracy: 0.7946 - val_loss: 0.4397 - val_accuracy: 0.8025 - 3s/epoch - 3ms/step\n",
      "Epoch 32/150\n",
      "1200/1200 - 5s - loss: 0.4542 - accuracy: 0.7941 - val_loss: 0.4372 - val_accuracy: 0.8001 - 5s/epoch - 4ms/step\n",
      "Epoch 33/150\n",
      "1200/1200 - 4s - loss: 0.4537 - accuracy: 0.7951 - val_loss: 0.4359 - val_accuracy: 0.8010 - 4s/epoch - 4ms/step\n",
      "Epoch 34/150\n",
      "1200/1200 - 3s - loss: 0.4549 - accuracy: 0.7946 - val_loss: 0.4380 - val_accuracy: 0.8011 - 3s/epoch - 3ms/step\n",
      "Epoch 35/150\n",
      "1200/1200 - 4s - loss: 0.4527 - accuracy: 0.7946 - val_loss: 0.4351 - val_accuracy: 0.8008 - 4s/epoch - 3ms/step\n",
      "Epoch 36/150\n",
      "1200/1200 - 4s - loss: 0.4517 - accuracy: 0.7958 - val_loss: 0.4324 - val_accuracy: 0.8014 - 4s/epoch - 3ms/step\n",
      "Epoch 37/150\n",
      "1200/1200 - 4s - loss: 0.4535 - accuracy: 0.7956 - val_loss: 0.4335 - val_accuracy: 0.8021 - 4s/epoch - 3ms/step\n",
      "Epoch 38/150\n",
      "1200/1200 - 4s - loss: 0.4514 - accuracy: 0.7954 - val_loss: 0.4359 - val_accuracy: 0.8034 - 4s/epoch - 3ms/step\n",
      "Epoch 39/150\n",
      "1200/1200 - 3s - loss: 0.4521 - accuracy: 0.7947 - val_loss: 0.4366 - val_accuracy: 0.7990 - 3s/epoch - 3ms/step\n",
      "Epoch 40/150\n",
      "1200/1200 - 4s - loss: 0.4513 - accuracy: 0.7948 - val_loss: 0.4330 - val_accuracy: 0.8008 - 4s/epoch - 3ms/step\n",
      "Epoch 41/150\n",
      "1200/1200 - 4s - loss: 0.4513 - accuracy: 0.7954 - val_loss: 0.4331 - val_accuracy: 0.8037 - 4s/epoch - 3ms/step\n",
      "Epoch 42/150\n",
      "1200/1200 - 4s - loss: 0.4525 - accuracy: 0.7942 - val_loss: 0.4331 - val_accuracy: 0.8014 - 4s/epoch - 3ms/step\n",
      "Epoch 43/150\n",
      "1200/1200 - 3s - loss: 0.4511 - accuracy: 0.7950 - val_loss: 0.4320 - val_accuracy: 0.8020 - 3s/epoch - 3ms/step\n",
      "Epoch 44/150\n",
      "1200/1200 - 4s - loss: 0.4504 - accuracy: 0.7953 - val_loss: 0.4366 - val_accuracy: 0.7969 - 4s/epoch - 4ms/step\n",
      "Epoch 45/150\n",
      "1200/1200 - 4s - loss: 0.4507 - accuracy: 0.7959 - val_loss: 0.4351 - val_accuracy: 0.7977 - 4s/epoch - 3ms/step\n",
      "Epoch 46/150\n",
      "1200/1200 - 4s - loss: 0.4513 - accuracy: 0.7939 - val_loss: 0.4337 - val_accuracy: 0.8041 - 4s/epoch - 3ms/step\n",
      "Epoch 47/150\n",
      "1200/1200 - 3s - loss: 0.4514 - accuracy: 0.7948 - val_loss: 0.4326 - val_accuracy: 0.8023 - 3s/epoch - 3ms/step\n",
      "Epoch 48/150\n",
      "1200/1200 - 3s - loss: 0.4495 - accuracy: 0.7972 - val_loss: 0.4340 - val_accuracy: 0.8006 - 3s/epoch - 3ms/step\n",
      "Epoch 49/150\n",
      "1200/1200 - 3s - loss: 0.4496 - accuracy: 0.7953 - val_loss: 0.4347 - val_accuracy: 0.7984 - 3s/epoch - 3ms/step\n",
      "Epoch 50/150\n",
      "1200/1200 - 3s - loss: 0.4504 - accuracy: 0.7950 - val_loss: 0.4340 - val_accuracy: 0.8011 - 3s/epoch - 2ms/step\n",
      "Epoch 51/150\n",
      "1200/1200 - 3s - loss: 0.4493 - accuracy: 0.7957 - val_loss: 0.4329 - val_accuracy: 0.8017 - 3s/epoch - 2ms/step\n",
      "Epoch 52/150\n",
      "1200/1200 - 3s - loss: 0.4486 - accuracy: 0.7966 - val_loss: 0.4342 - val_accuracy: 0.7994 - 3s/epoch - 2ms/step\n",
      "Epoch 53/150\n",
      "1200/1200 - 3s - loss: 0.4489 - accuracy: 0.7963 - val_loss: 0.4320 - val_accuracy: 0.8015 - 3s/epoch - 3ms/step\n",
      "Epoch 54/150\n",
      "1200/1200 - 4s - loss: 0.4491 - accuracy: 0.7970 - val_loss: 0.4298 - val_accuracy: 0.8007 - 4s/epoch - 3ms/step\n",
      "Epoch 55/150\n",
      "1200/1200 - 4s - loss: 0.4499 - accuracy: 0.7967 - val_loss: 0.4306 - val_accuracy: 0.8018 - 4s/epoch - 4ms/step\n",
      "Epoch 56/150\n",
      "1200/1200 - 3s - loss: 0.4482 - accuracy: 0.7969 - val_loss: 0.4298 - val_accuracy: 0.8032 - 3s/epoch - 3ms/step\n",
      "Epoch 57/150\n",
      "1200/1200 - 4s - loss: 0.4489 - accuracy: 0.7954 - val_loss: 0.4344 - val_accuracy: 0.8018 - 4s/epoch - 3ms/step\n",
      "Epoch 58/150\n",
      "1200/1200 - 3s - loss: 0.4484 - accuracy: 0.7961 - val_loss: 0.4303 - val_accuracy: 0.7993 - 3s/epoch - 3ms/step\n",
      "Epoch 59/150\n",
      "1200/1200 - 3s - loss: 0.4479 - accuracy: 0.7962 - val_loss: 0.4316 - val_accuracy: 0.8027 - 3s/epoch - 3ms/step\n",
      "Epoch 60/150\n",
      "1200/1200 - 3s - loss: 0.4479 - accuracy: 0.7969 - val_loss: 0.4299 - val_accuracy: 0.8035 - 3s/epoch - 3ms/step\n",
      "Epoch 61/150\n",
      "1200/1200 - 3s - loss: 0.4482 - accuracy: 0.7963 - val_loss: 0.4345 - val_accuracy: 0.7985 - 3s/epoch - 2ms/step\n",
      "Epoch 62/150\n",
      "1200/1200 - 3s - loss: 0.4483 - accuracy: 0.7959 - val_loss: 0.4301 - val_accuracy: 0.8032 - 3s/epoch - 2ms/step\n",
      "Epoch 63/150\n",
      "1200/1200 - 3s - loss: 0.4483 - accuracy: 0.7959 - val_loss: 0.4331 - val_accuracy: 0.8008 - 3s/epoch - 2ms/step\n",
      "Epoch 64/150\n",
      "1200/1200 - 3s - loss: 0.4471 - accuracy: 0.7963 - val_loss: 0.4346 - val_accuracy: 0.8033 - 3s/epoch - 2ms/step\n",
      "Epoch 65/150\n",
      "1200/1200 - 3s - loss: 0.4478 - accuracy: 0.7972 - val_loss: 0.4310 - val_accuracy: 0.8001 - 3s/epoch - 2ms/step\n",
      "Epoch 66/150\n",
      "1200/1200 - 3s - loss: 0.4480 - accuracy: 0.7961 - val_loss: 0.4309 - val_accuracy: 0.8008 - 3s/epoch - 2ms/step\n",
      "Epoch 67/150\n",
      "1200/1200 - 3s - loss: 0.4476 - accuracy: 0.7960 - val_loss: 0.4302 - val_accuracy: 0.8026 - 3s/epoch - 2ms/step\n",
      "Epoch 68/150\n",
      "1200/1200 - 3s - loss: 0.4466 - accuracy: 0.7963 - val_loss: 0.4299 - val_accuracy: 0.8038 - 3s/epoch - 2ms/step\n",
      "Epoch 69/150\n",
      "1200/1200 - 3s - loss: 0.4481 - accuracy: 0.7963 - val_loss: 0.4291 - val_accuracy: 0.8009 - 3s/epoch - 2ms/step\n",
      "Epoch 70/150\n",
      "1200/1200 - 3s - loss: 0.4465 - accuracy: 0.7963 - val_loss: 0.4284 - val_accuracy: 0.8017 - 3s/epoch - 2ms/step\n",
      "Epoch 71/150\n",
      "1200/1200 - 3s - loss: 0.4462 - accuracy: 0.7969 - val_loss: 0.4325 - val_accuracy: 0.7983 - 3s/epoch - 2ms/step\n",
      "Epoch 72/150\n",
      "1200/1200 - 3s - loss: 0.4482 - accuracy: 0.7948 - val_loss: 0.4293 - val_accuracy: 0.8013 - 3s/epoch - 2ms/step\n",
      "Epoch 73/150\n",
      "1200/1200 - 3s - loss: 0.4468 - accuracy: 0.7966 - val_loss: 0.4311 - val_accuracy: 0.7993 - 3s/epoch - 2ms/step\n",
      "Epoch 74/150\n",
      "1200/1200 - 3s - loss: 0.4460 - accuracy: 0.7969 - val_loss: 0.4288 - val_accuracy: 0.7989 - 3s/epoch - 2ms/step\n",
      "Epoch 75/150\n",
      "1200/1200 - 3s - loss: 0.4471 - accuracy: 0.7967 - val_loss: 0.4283 - val_accuracy: 0.8003 - 3s/epoch - 2ms/step\n",
      "Epoch 76/150\n",
      "1200/1200 - 3s - loss: 0.4458 - accuracy: 0.7960 - val_loss: 0.4292 - val_accuracy: 0.7988 - 3s/epoch - 2ms/step\n",
      "Epoch 77/150\n",
      "1200/1200 - 3s - loss: 0.4461 - accuracy: 0.7953 - val_loss: 0.4298 - val_accuracy: 0.8016 - 3s/epoch - 2ms/step\n",
      "Epoch 78/150\n",
      "1200/1200 - 3s - loss: 0.4457 - accuracy: 0.7965 - val_loss: 0.4291 - val_accuracy: 0.8006 - 3s/epoch - 2ms/step\n",
      "Epoch 79/150\n",
      "1200/1200 - 3s - loss: 0.4470 - accuracy: 0.7958 - val_loss: 0.4278 - val_accuracy: 0.8028 - 3s/epoch - 2ms/step\n",
      "Epoch 80/150\n",
      "1200/1200 - 3s - loss: 0.4463 - accuracy: 0.7959 - val_loss: 0.4298 - val_accuracy: 0.8031 - 3s/epoch - 2ms/step\n",
      "Epoch 81/150\n",
      "1200/1200 - 3s - loss: 0.4459 - accuracy: 0.7962 - val_loss: 0.4286 - val_accuracy: 0.8023 - 3s/epoch - 2ms/step\n",
      "Epoch 82/150\n",
      "1200/1200 - 3s - loss: 0.4465 - accuracy: 0.7955 - val_loss: 0.4288 - val_accuracy: 0.8030 - 3s/epoch - 2ms/step\n",
      "Epoch 83/150\n",
      "1200/1200 - 3s - loss: 0.4450 - accuracy: 0.7971 - val_loss: 0.4259 - val_accuracy: 0.8034 - 3s/epoch - 2ms/step\n",
      "Epoch 84/150\n",
      "1200/1200 - 3s - loss: 0.4446 - accuracy: 0.7968 - val_loss: 0.4286 - val_accuracy: 0.8000 - 3s/epoch - 2ms/step\n",
      "Epoch 85/150\n",
      "1200/1200 - 3s - loss: 0.4462 - accuracy: 0.7958 - val_loss: 0.4311 - val_accuracy: 0.8007 - 3s/epoch - 2ms/step\n",
      "Epoch 86/150\n",
      "1200/1200 - 3s - loss: 0.4463 - accuracy: 0.7974 - val_loss: 0.4287 - val_accuracy: 0.8012 - 3s/epoch - 2ms/step\n",
      "Epoch 87/150\n",
      "1200/1200 - 3s - loss: 0.4456 - accuracy: 0.7964 - val_loss: 0.4305 - val_accuracy: 0.8009 - 3s/epoch - 2ms/step\n",
      "Epoch 88/150\n",
      "1200/1200 - 3s - loss: 0.4457 - accuracy: 0.7968 - val_loss: 0.4294 - val_accuracy: 0.8034 - 3s/epoch - 2ms/step\n",
      "Epoch 89/150\n",
      "1200/1200 - 3s - loss: 0.4453 - accuracy: 0.7971 - val_loss: 0.4270 - val_accuracy: 0.8024 - 3s/epoch - 2ms/step\n",
      "Epoch 90/150\n",
      "1200/1200 - 3s - loss: 0.4455 - accuracy: 0.7962 - val_loss: 0.4313 - val_accuracy: 0.8003 - 3s/epoch - 2ms/step\n",
      "Epoch 91/150\n",
      "1200/1200 - 3s - loss: 0.4453 - accuracy: 0.7958 - val_loss: 0.4295 - val_accuracy: 0.8002 - 3s/epoch - 2ms/step\n",
      "Epoch 92/150\n",
      "1200/1200 - 3s - loss: 0.4445 - accuracy: 0.7970 - val_loss: 0.4271 - val_accuracy: 0.8031 - 3s/epoch - 2ms/step\n",
      "Epoch 93/150\n",
      "1200/1200 - 3s - loss: 0.4455 - accuracy: 0.7961 - val_loss: 0.4283 - val_accuracy: 0.8024 - 3s/epoch - 2ms/step\n",
      "Epoch 94/150\n",
      "1200/1200 - 3s - loss: 0.4451 - accuracy: 0.7962 - val_loss: 0.4293 - val_accuracy: 0.8016 - 3s/epoch - 2ms/step\n",
      "Epoch 95/150\n",
      "1200/1200 - 3s - loss: 0.4463 - accuracy: 0.7960 - val_loss: 0.4322 - val_accuracy: 0.7986 - 3s/epoch - 2ms/step\n",
      "Epoch 96/150\n",
      "1200/1200 - 3s - loss: 0.4453 - accuracy: 0.7960 - val_loss: 0.4299 - val_accuracy: 0.8022 - 3s/epoch - 2ms/step\n",
      "Epoch 97/150\n",
      "1200/1200 - 3s - loss: 0.4455 - accuracy: 0.7959 - val_loss: 0.4278 - val_accuracy: 0.8026 - 3s/epoch - 2ms/step\n",
      "Epoch 98/150\n",
      "1200/1200 - 3s - loss: 0.4440 - accuracy: 0.7963 - val_loss: 0.4265 - val_accuracy: 0.7992 - 3s/epoch - 2ms/step\n",
      "Epoch 99/150\n",
      "1200/1200 - 3s - loss: 0.4438 - accuracy: 0.7967 - val_loss: 0.4267 - val_accuracy: 0.8046 - 3s/epoch - 2ms/step\n",
      "Epoch 100/150\n",
      "1200/1200 - 3s - loss: 0.4452 - accuracy: 0.7971 - val_loss: 0.4263 - val_accuracy: 0.8026 - 3s/epoch - 2ms/step\n",
      "Epoch 101/150\n",
      "1200/1200 - 3s - loss: 0.4445 - accuracy: 0.7963 - val_loss: 0.4271 - val_accuracy: 0.8019 - 3s/epoch - 2ms/step\n",
      "Epoch 102/150\n",
      "1200/1200 - 3s - loss: 0.4438 - accuracy: 0.7976 - val_loss: 0.4264 - val_accuracy: 0.8015 - 3s/epoch - 2ms/step\n",
      "Epoch 103/150\n",
      "1200/1200 - 3s - loss: 0.4441 - accuracy: 0.7972 - val_loss: 0.4250 - val_accuracy: 0.8047 - 3s/epoch - 2ms/step\n",
      "Epoch 104/150\n",
      "1200/1200 - 3s - loss: 0.4428 - accuracy: 0.7976 - val_loss: 0.4314 - val_accuracy: 0.8012 - 3s/epoch - 2ms/step\n",
      "Epoch 105/150\n",
      "1200/1200 - 3s - loss: 0.4457 - accuracy: 0.7970 - val_loss: 0.4251 - val_accuracy: 0.8006 - 3s/epoch - 2ms/step\n",
      "Epoch 106/150\n",
      "1200/1200 - 3s - loss: 0.4429 - accuracy: 0.7969 - val_loss: 0.4274 - val_accuracy: 0.8042 - 3s/epoch - 2ms/step\n",
      "Epoch 107/150\n",
      "1200/1200 - 3s - loss: 0.4445 - accuracy: 0.7963 - val_loss: 0.4274 - val_accuracy: 0.8018 - 3s/epoch - 2ms/step\n",
      "Epoch 108/150\n",
      "1200/1200 - 3s - loss: 0.4446 - accuracy: 0.7963 - val_loss: 0.4309 - val_accuracy: 0.7999 - 3s/epoch - 2ms/step\n",
      "Epoch 109/150\n",
      "1200/1200 - 3s - loss: 0.4435 - accuracy: 0.7972 - val_loss: 0.4249 - val_accuracy: 0.8015 - 3s/epoch - 2ms/step\n",
      "Epoch 110/150\n",
      "1200/1200 - 3s - loss: 0.4459 - accuracy: 0.7960 - val_loss: 0.4294 - val_accuracy: 0.7998 - 3s/epoch - 2ms/step\n",
      "Epoch 111/150\n",
      "1200/1200 - 3s - loss: 0.4435 - accuracy: 0.7981 - val_loss: 0.4302 - val_accuracy: 0.8018 - 3s/epoch - 2ms/step\n",
      "Epoch 112/150\n",
      "1200/1200 - 3s - loss: 0.4441 - accuracy: 0.7968 - val_loss: 0.4306 - val_accuracy: 0.8024 - 3s/epoch - 2ms/step\n",
      "Epoch 113/150\n",
      "1200/1200 - 3s - loss: 0.4429 - accuracy: 0.7976 - val_loss: 0.4254 - val_accuracy: 0.8040 - 3s/epoch - 2ms/step\n",
      "Epoch 114/150\n",
      "1200/1200 - 3s - loss: 0.4443 - accuracy: 0.7954 - val_loss: 0.4277 - val_accuracy: 0.8007 - 3s/epoch - 2ms/step\n",
      "Epoch 115/150\n",
      "1200/1200 - 3s - loss: 0.4433 - accuracy: 0.7973 - val_loss: 0.4267 - val_accuracy: 0.7987 - 3s/epoch - 2ms/step\n",
      "Epoch 116/150\n",
      "1200/1200 - 3s - loss: 0.4426 - accuracy: 0.7978 - val_loss: 0.4281 - val_accuracy: 0.7999 - 3s/epoch - 2ms/step\n",
      "Epoch 117/150\n",
      "1200/1200 - 3s - loss: 0.4428 - accuracy: 0.7984 - val_loss: 0.4263 - val_accuracy: 0.8013 - 3s/epoch - 2ms/step\n",
      "Epoch 118/150\n",
      "1200/1200 - 3s - loss: 0.4439 - accuracy: 0.7974 - val_loss: 0.4296 - val_accuracy: 0.8016 - 3s/epoch - 2ms/step\n",
      "Epoch 119/150\n",
      "1200/1200 - 3s - loss: 0.4436 - accuracy: 0.7974 - val_loss: 0.4281 - val_accuracy: 0.8021 - 3s/epoch - 2ms/step\n",
      "Epoch 120/150\n",
      "1200/1200 - 3s - loss: 0.4440 - accuracy: 0.7965 - val_loss: 0.4300 - val_accuracy: 0.7958 - 3s/epoch - 2ms/step\n",
      "Epoch 121/150\n",
      "1200/1200 - 3s - loss: 0.4436 - accuracy: 0.7959 - val_loss: 0.4285 - val_accuracy: 0.8010 - 3s/epoch - 2ms/step\n",
      "Epoch 122/150\n",
      "1200/1200 - 3s - loss: 0.4438 - accuracy: 0.7966 - val_loss: 0.4248 - val_accuracy: 0.8027 - 3s/epoch - 2ms/step\n",
      "Epoch 123/150\n",
      "1200/1200 - 3s - loss: 0.4427 - accuracy: 0.7971 - val_loss: 0.4278 - val_accuracy: 0.7996 - 3s/epoch - 2ms/step\n",
      "Epoch 124/150\n",
      "1200/1200 - 3s - loss: 0.4425 - accuracy: 0.7962 - val_loss: 0.4244 - val_accuracy: 0.8014 - 3s/epoch - 2ms/step\n",
      "Epoch 125/150\n",
      "1200/1200 - 3s - loss: 0.4443 - accuracy: 0.7965 - val_loss: 0.4274 - val_accuracy: 0.8012 - 3s/epoch - 2ms/step\n",
      "Epoch 126/150\n",
      "1200/1200 - 3s - loss: 0.4441 - accuracy: 0.7966 - val_loss: 0.4297 - val_accuracy: 0.8011 - 3s/epoch - 2ms/step\n",
      "Epoch 127/150\n",
      "1200/1200 - 3s - loss: 0.4431 - accuracy: 0.7963 - val_loss: 0.4268 - val_accuracy: 0.8024 - 3s/epoch - 2ms/step\n",
      "Epoch 128/150\n",
      "1200/1200 - 3s - loss: 0.4440 - accuracy: 0.7972 - val_loss: 0.4268 - val_accuracy: 0.8026 - 3s/epoch - 2ms/step\n",
      "Epoch 129/150\n",
      "1200/1200 - 3s - loss: 0.4426 - accuracy: 0.7966 - val_loss: 0.4260 - val_accuracy: 0.8031 - 3s/epoch - 2ms/step\n",
      "Epoch 130/150\n",
      "1200/1200 - 3s - loss: 0.4421 - accuracy: 0.7967 - val_loss: 0.4260 - val_accuracy: 0.8022 - 3s/epoch - 2ms/step\n",
      "Epoch 131/150\n",
      "1200/1200 - 3s - loss: 0.4424 - accuracy: 0.7973 - val_loss: 0.4248 - val_accuracy: 0.8037 - 3s/epoch - 2ms/step\n",
      "Epoch 132/150\n",
      "1200/1200 - 3s - loss: 0.4425 - accuracy: 0.7972 - val_loss: 0.4279 - val_accuracy: 0.8004 - 3s/epoch - 2ms/step\n",
      "Epoch 133/150\n",
      "1200/1200 - 3s - loss: 0.4424 - accuracy: 0.7966 - val_loss: 0.4274 - val_accuracy: 0.8031 - 3s/epoch - 2ms/step\n",
      "Epoch 134/150\n",
      "1200/1200 - 3s - loss: 0.4435 - accuracy: 0.7963 - val_loss: 0.4273 - val_accuracy: 0.8005 - 3s/epoch - 2ms/step\n",
      "Epoch 135/150\n",
      "1200/1200 - 3s - loss: 0.4433 - accuracy: 0.7970 - val_loss: 0.4282 - val_accuracy: 0.7989 - 3s/epoch - 2ms/step\n",
      "Epoch 136/150\n",
      "1200/1200 - 3s - loss: 0.4424 - accuracy: 0.7960 - val_loss: 0.4274 - val_accuracy: 0.8021 - 3s/epoch - 2ms/step\n",
      "Epoch 137/150\n",
      "1200/1200 - 3s - loss: 0.4421 - accuracy: 0.7955 - val_loss: 0.4262 - val_accuracy: 0.8053 - 3s/epoch - 2ms/step\n",
      "Epoch 138/150\n",
      "1200/1200 - 3s - loss: 0.4410 - accuracy: 0.7974 - val_loss: 0.4247 - val_accuracy: 0.8020 - 3s/epoch - 2ms/step\n",
      "Epoch 139/150\n",
      "1200/1200 - 3s - loss: 0.4424 - accuracy: 0.7968 - val_loss: 0.4240 - val_accuracy: 0.8018 - 3s/epoch - 2ms/step\n",
      "Epoch 140/150\n",
      "1200/1200 - 3s - loss: 0.4429 - accuracy: 0.7965 - val_loss: 0.4252 - val_accuracy: 0.8040 - 3s/epoch - 2ms/step\n",
      "Epoch 141/150\n",
      "1200/1200 - 3s - loss: 0.4437 - accuracy: 0.7969 - val_loss: 0.4255 - val_accuracy: 0.8001 - 3s/epoch - 2ms/step\n",
      "Epoch 142/150\n",
      "1200/1200 - 3s - loss: 0.4417 - accuracy: 0.7970 - val_loss: 0.4259 - val_accuracy: 0.8010 - 3s/epoch - 2ms/step\n",
      "Epoch 143/150\n",
      "1200/1200 - 3s - loss: 0.4422 - accuracy: 0.7966 - val_loss: 0.4245 - val_accuracy: 0.8039 - 3s/epoch - 3ms/step\n",
      "Epoch 144/150\n",
      "1200/1200 - 4s - loss: 0.4411 - accuracy: 0.7979 - val_loss: 0.4246 - val_accuracy: 0.8062 - 4s/epoch - 3ms/step\n",
      "Epoch 145/150\n",
      "1200/1200 - 4s - loss: 0.4421 - accuracy: 0.7971 - val_loss: 0.4260 - val_accuracy: 0.8021 - 4s/epoch - 3ms/step\n",
      "Epoch 146/150\n",
      "1200/1200 - 3s - loss: 0.4433 - accuracy: 0.7959 - val_loss: 0.4251 - val_accuracy: 0.8040 - 3s/epoch - 3ms/step\n",
      "Epoch 147/150\n",
      "1200/1200 - 3s - loss: 0.4423 - accuracy: 0.7972 - val_loss: 0.4248 - val_accuracy: 0.8013 - 3s/epoch - 3ms/step\n",
      "Epoch 148/150\n",
      "1200/1200 - 3s - loss: 0.4420 - accuracy: 0.7966 - val_loss: 0.4244 - val_accuracy: 0.8050 - 3s/epoch - 3ms/step\n",
      "Epoch 149/150\n",
      "1200/1200 - 4s - loss: 0.4427 - accuracy: 0.7960 - val_loss: 0.4269 - val_accuracy: 0.8030 - 4s/epoch - 3ms/step\n",
      "Epoch 150/150\n",
      "1200/1200 - 3s - loss: 0.4426 - accuracy: 0.7965 - val_loss: 0.4242 - val_accuracy: 0.8038 - 3s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Construire le modèle avec des ajustements\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(y_train_encoded.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiler le modèle avec un taux d'apprentissage ajusté\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle avec une taille de lot ajustée\n",
    "history = model.fit(X_train, y_train_encoded, epochs=150, batch_size=64, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8010250926017761\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test_encoded, verbose=0)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7696891407617301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Exemple hypothétique de construction de X_fragmented\n",
    "\n",
    "X_fragmented_list = []  # Pour stocker les fragments\n",
    "\n",
    "# Parcourir chaque semaine dans les données\n",
    "for index, row in data.iterrows():\n",
    "    for i in range(1, len(columns) + 1):  # 'columns' contient les noms des demi-journées\n",
    "        fragment = row[:i].tolist()  # Prendre les profits jusqu'à la demi-journée i\n",
    "        fragment += [0] * (len(columns) - i)  # Remplir le reste du fragment avec des zéros\n",
    "        X_fragmented_list.append(fragment)\n",
    "        y_expanded_list = []\n",
    "\n",
    "# Pour chaque semaine dans les données\n",
    "for label in y:\n",
    "    for _ in range(len(columns)):  # Répéter le label pour chaque fragment partiel créé pour la semaine\n",
    "        y_expanded_list.append(label)\n",
    "\n",
    "# Convertir en array numpy pour l'utilisation avec sklearn\n",
    "y_expanded = np.array(y_expanded_list)\n",
    "\n",
    "\n",
    "# Convertir en ndarray ou DataFrame pour l'utilisation avec sklearn\n",
    "X_fragmented = np.array(X_fragmented_list)\n",
    "\n",
    "# Supposons que X_fragmented représente vos caractéristiques fragmentées et y les labels de clusters correspondants\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fragmented, y_expanded, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=426,\n",
    "    max_depth=15,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=10,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres :  {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 426}\n",
      "Meilleure accuracy :  0.7725283883737889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Définition de la grille de recherche\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(3, 20),\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 11),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Création du modèle Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Recherche aléatoire avec validation croisée\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=20, cv=5, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Entraînement\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs paramètres et accuracy\n",
    "print(\"Meilleurs paramètres : \", random_search.best_params_)\n",
    "print(\"Meilleure accuracy : \", random_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
